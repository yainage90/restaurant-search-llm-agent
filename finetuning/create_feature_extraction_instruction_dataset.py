# -*- coding: utf-8 -*-
"""
íŠ¹ì§• ì¶”ì¶œ ê²½ëŸ‰ ëª¨ë¸ íŒŒì¸íŠœë‹ì„ ìœ„í•œ instruction dataset ìƒì„± ìŠ¤í¬ë¦½íŠ¸
data/featured_restaurantsì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ instruction-output ìŒì„ ìƒì„±
"""

import os
import json
import argparse
from typing import Any
from tqdm import tqdm


SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì‹ë‹¹ ì •ë³´(ì†Œê°œê¸€, ë¦¬ë·°)ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ë§›ì§‘ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì¶”ì¶œëœ ì •ë³´ëŠ” ì‹ë‹¹ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
"""

EXTRACT_FEATURES_PROMPT = """
ì‹ë‹¹ ì†Œê°œê¸€ê³¼ ì‚¬ìš©ì ë¦¬ë·°ì—ì„œ ì•„ë˜ ê° í•­ëª©ì— í•´ë‹¹í•˜ëŠ” íŠ¹ì§• í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
1. `review_food`: ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë©”ë‰´ë‚˜ ìŒì‹ í‚¤ì›Œë“œ  (ì˜ˆ: íŒŒìŠ¤íƒ€, ìŠ¤í…Œì´í¬, ë–¡ë³¶ì´)
2. `convenience`: ì‹ë‹¹ì—ì„œ ì œê³µí•˜ëŠ” ê¸ì •ì ì¸ í¸ì˜ ë° ì„œë¹„ìŠ¤ (ì˜ˆ: ì£¼ì°¨, ë°œë ›, ë°°ë‹¬, í¬ì¥, ì˜ˆì•½, ë£¸, ì½œí‚¤ì§€, ë°˜ë ¤ë™ë¬¼, ì™€ì´íŒŒì´, 24ì‹œ, êµ¬ì›Œì¤Œ)
3. `atmosphere`: ë¶„ìœ„ê¸° (ì˜ˆ: ì´êµ­ì ì¸, ë¡œë§¨í‹±í•œ, ë·°ë§›ì§‘, ë…¸í¬, ì¡°ìš©í•œ, ì‹œëŒë²…ì í•œ)
4. `occasion`: ë°©ë¬¸ ëª©ì  (ì˜ˆ: ë°ì´íŠ¸, ê¸°ë…ì¼, íšŒì‹, ë‹¨ì²´, í˜¼ë°¥, í˜¼ìˆ )
5. `features`: ê¸°íƒ€ íŠ¹ì§• (ì˜ˆ: ë„“ì€ê³µê°„, ê°€ì„±ë¹„)

**ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

**ì¶”ì¶œ ê°€ì´ë“œë¼ì¸:**
- ê° í•­ëª©ì— ëŒ€í•´ 10ê°œ ì´í•˜ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ì—¬ëŸ¬ ë¦¬ë·°ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤.
- 'ì¸ìƒ'ì´ ë“¤ì–´ê°€ëŠ” í‚¤ì›Œë“œëŠ” ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
- ì ˆëŒ€ë¡œ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¤‘ë³µí•´ì„œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
- ë¶€ì •ì ì¸ ë‚´ìš©ì€ í¸ì˜ ê¸°ëŠ¥ì´ ì•„ë‹˜: 'ì§ì ‘ êµ¬ì›Œë¨¹ì–´ì•¼ í•¨'ì´ë‚˜ 'ì£¼ì°¨ ê³µê°„ ì—†ìŒ'ê³¼ ê°™ì´ ê³ ê°ì—ê²Œ ë¶ˆí¸ì„ ì£¼ê±°ë‚˜, ì‹ë‹¹ì—ì„œ ì œê³µí•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ëŠ” `convenience` í•­ëª©ì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ë¦¬ë·°ë‚˜ ì†Œê°œê¸€ì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ë‹¨ì–´ë§Œìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ 'ì „í™”í•˜ê³  ë°©ë¬¸'ì„ 'ì˜ˆì•½'ìœ¼ë¡œ í•´ì„í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¬¸ë§¥ì„ í™•ì¥í•˜ì—¬ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”.
- ëª¨ë“  í‚¤ì›Œë“œë¥¼ ì¢…í•©í•˜ì—¬ ì¤‘ë³µì„ ì œê±°í•´ì£¼ì„¸ìš”.
- í•­ëª©ì— í‚¤ì›Œë“œê°€ ì—†ë‹¤ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.
- ì‹ë‹¹ ì†Œê°œê¸€ì—ì„œ ë©”ë‰´ëŠ” ì œì™¸ í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ íŠ¹ì§•ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

**JSON í˜•ì‹:**
{{
    "review_food": list,
    "convenience": list,
    "atmosphere": list,
    "occasion": list,
    "features": list,
}}

ìœ„ ê°€ì´ë“œë¼ì¸ê³¼ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬, ì•„ë˜ì˜ ì‹¤ì œ ì…ë ¥ ë°ì´í„°ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì‹ë‹¹ ì†Œê°œê¸€:
{description}

ì‚¬ìš©ì ë¦¬ë·°:
{reviews}
"""


def create_instruction_dataset_entry(featured_data: dict[str, Any]) -> dict[str, Any]:
    """
    featured_restaurants ë°ì´í„°ë¥¼ instruction dataset í˜•íƒœë¡œ ë³€í™˜
    """
    # ë¦¬ë·° í…ìŠ¤íŠ¸ ê²°í•© (ìµœëŒ€ 30ê°œ ë¦¬ë·°ë§Œ ì‚¬ìš©)
    num_reviews_to_use = 30
    reviews = featured_data.get("reviews", [])
    reviews = [review for review in reviews if len(review) >= 15]
    review_text = "\n".join(reviews[:num_reviews_to_use])
    if len(review_text) > 100 * num_reviews_to_use:
        review_text = review_text[:100 * num_reviews_to_use]
    
    # ì…ë ¥ í”„ë¡¬í”„íŠ¸ ìƒì„±
    user_prompt = EXTRACT_FEATURES_PROMPT.format(
        description=featured_data.get("description", ""),
        reviews=review_text
    )
    
    # ì¶œë ¥ JSON ìƒì„±
    output_json = {
        "review_food": featured_data.get("review_food", []),
        "convenience": featured_data.get("convenience", []),
        "atmosphere": featured_data.get("atmosphere", []),
        "occasion": featured_data.get("occasion", []),
        "features": featured_data.get("features", [])
    }
    
    # instruction dataset í˜•íƒœë¡œ ë³€í™˜
    instruction_entry = {
        "messages": [
            {
                "role": "system",
                "content": SYSTEM_PROMPT
            },
            {
                "role": "user", 
                "content": user_prompt
            },
            {
                "role": "assistant",
                "content": json.dumps(output_json, ensure_ascii=False)
            }
        ]
    }
    
    return instruction_entry


def process_file(input_file_path: str, output_file_path: str, max_samples: int | None = None):
    """
    ë‹¨ì¼ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ instruction datasetìœ¼ë¡œ ë³€í™˜
    """
    print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {os.path.basename(input_file_path)}")
    
    # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚°
    total_records = 0
    with open(input_file_path, "r", encoding="utf-8") as f_in:
        for _ in f_in:
            total_records += 1
    
    # max_samples ì œí•œì´ ìˆëŠ” ê²½ìš° ì ìš©
    target_samples = min(max_samples, total_records) if max_samples else total_records
    
    print(f"ì „ì²´: {total_records}ê°œ | ëª©í‘œ: {target_samples}ê°œ")
    
    # íŒŒì¼ ì²˜ë¦¬
    with open(input_file_path, "r", encoding="utf-8") as f_in:
        with open(output_file_path, "a", encoding="utf-8") as f_out:
            progress_bar = tqdm(
                total=total_records,
                desc="ë³€í™˜ì¤‘",
                unit="ê°œ",
                ncols=80,
                bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
            )
            
            samples_added = 0
            for line in f_in:
                featured_data = json.loads(line)
                
                instruction_entry = create_instruction_dataset_entry(featured_data)
                f_out.write(f"{json.dumps(instruction_entry, ensure_ascii=False)}\n")
                f_out.flush()
                
                samples_added += 1
                progress_bar.update(1)
                    
            progress_bar.close()
    
    print(f"âœ… ì™„ë£Œ - {samples_added}ê°œ ë³€í™˜ë¨\n")


def main():
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    INPUT_DIR = os.path.join(BASE_DIR, "../data/featured_restaurants")
    OUTPUT_DIR = os.path.join(BASE_DIR, "../data/feature_extraction_instruction_dataset")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ì…ë ¥ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  part íŒŒì¼ ì°¾ê¸°
    input_files = [f for f in os.listdir(INPUT_DIR) if f.startswith("part-") and f.endswith(".jsonl")]
    input_files.sort()
    
    print(f"ğŸ“ ì´ {len(input_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘")
    print(f"ğŸ¯ ê° íŒŒì¼ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜: {args.max_samples_per_file if args.max_samples_per_file else 'ì œí•œì—†ìŒ'}")
    print()
    
    total_samples = 0
    
    for file_idx, input_filename in enumerate(input_files, 1):
        input_file_path = os.path.join(INPUT_DIR, input_filename)
        output_file_path = os.path.join(OUTPUT_DIR, input_filename)
        
        print(f"[{file_idx}/{len(input_files)}]", end=" ")
        
        # íŒŒì¼ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œì´ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
        if args.max_files and file_idx > args.max_files:
            break
            
        process_file(input_file_path, output_file_path, args.max_samples_per_file)
    
    # ìµœì¢… í†µê³„
    print("ğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    total_samples = 0
    for filename in os.listdir(OUTPUT_DIR):
        if filename.startswith("part-") and filename.endswith(".jsonl"):
            with open(os.path.join(OUTPUT_DIR, filename), "r", encoding="utf-8") as f:
                total_samples += sum(1 for _ in f)
    
    print(f"ğŸ“Š ì´ ìƒì„±ëœ instruction ìƒ˜í”Œ ìˆ˜: {total_samples:,}ê°œ")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="íŠ¹ì§• ì¶”ì¶œ instruction dataset ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--max-samples-per-file",
        type=int,
        default=None,
        help="ê° íŒŒì¼ë‹¹ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: ì œí•œì—†ìŒ)"
    )
    parser.add_argument(
        "--max-files",
        type=int,
        default=None,
        help="ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (ê¸°ë³¸ê°’: ì „ì²´)"
    )
    
    args = parser.parse_args()
    
    main()