"""
ì‹ë‹¹ ë°ì´í„°ë¥¼ ê²€ìƒ‰ìš© ë¬¸ì„œë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
README.mdì˜ ì„¹ì…˜ 5ì— ë”°ë¼ ì „ì²˜ë¦¬ ë° LLM ê¸°ë°˜ ì •ë³´ ì¶”ì¶œì„ ìˆ˜í–‰
"""

import os
import json
import re
import argparse
from typing import Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv
from google import genai
from openai import OpenAI
from pydantic import BaseModel
from tqdm import tqdm


load_dotenv()

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì‹ë‹¹ ì •ë³´(ì†Œê°œê¸€, ë¦¬ë·°)ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ë§›ì§‘ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì¶”ì¶œëœ ì •ë³´ëŠ” ì‹ë‹¹ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
"""

EXTRACT_FEATURES_PROMPT = """
ì‹ë‹¹ ì†Œê°œê¸€ê³¼ ì‚¬ìš©ì ë¦¬ë·°ì—ì„œ ì•„ë˜ ê° í•­ëª©ì— í•´ë‹¹í•˜ëŠ” íŠ¹ì§• í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
1. `review_food`: ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë©”ë‰´ë‚˜ ìŒì‹ í‚¤ì›Œë“œ  (ì˜ˆ: íŒŒìŠ¤íƒ€, ìŠ¤í…Œì´í¬, ë–¡ë³¶ì´)
2. `convenience`: ì‹ë‹¹ì—ì„œ ì œê³µí•˜ëŠ” ê¸ì •ì ì¸ í¸ì˜ ë° ì„œë¹„ìŠ¤ (ì˜ˆ: ì£¼ì°¨, ë°œë ›, ë°°ë‹¬, í¬ì¥, ì˜ˆì•½, ë£¸, ì½œí‚¤ì§€, ë°˜ë ¤ë™ë¬¼, ì™€ì´íŒŒì´, 24ì‹œ, êµ¬ì›Œì¤Œ)
3. `atmosphere`: ë¶„ìœ„ê¸° (ì˜ˆ: ì´êµ­ì ì¸, ë¡œë§¨í‹±í•œ, ë·°ë§›ì§‘, ë…¸í¬, ì¡°ìš©í•œ, ì‹œëŒë²…ì í•œ)
4. `occasion`: ë°©ë¬¸ ëª©ì  (ì˜ˆ: ë°ì´íŠ¸, ê¸°ë…ì¼, íšŒì‹, ë‹¨ì²´, í˜¼ë°¥, í˜¼ìˆ )
5. `features`: ê¸°íƒ€ íŠ¹ì§• (ì˜ˆ: ë„“ì€ê³µê°„, ê°€ì„±ë¹„)

**ì¤‘ìš”: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

**ì¶”ì¶œ ê°€ì´ë“œë¼ì¸:**
- ê° í•­ëª©ì— ëŒ€í•´ 10ê°œ ì´í•˜ì˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ì—¬ëŸ¬ ë¦¬ë·°ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì–¸ê¸‰ë˜ëŠ” ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤.
- 'ì¸ìƒ'ì´ ë“¤ì–´ê°€ëŠ” í‚¤ì›Œë“œëŠ” ì¶”ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
- ì ˆëŒ€ë¡œ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¤‘ë³µí•´ì„œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.
- ë¶€ì •ì ì¸ ë‚´ìš©ì€ í¸ì˜ ê¸°ëŠ¥ì´ ì•„ë‹˜: 'ì§ì ‘ êµ¬ì›Œë¨¹ì–´ì•¼ í•¨'ì´ë‚˜ 'ì£¼ì°¨ ê³µê°„ ì—†ìŒ'ê³¼ ê°™ì´ ê³ ê°ì—ê²Œ ë¶ˆí¸ì„ ì£¼ê±°ë‚˜, ì‹ë‹¹ì—ì„œ ì œê³µí•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ëŠ” `convenience` í•­ëª©ì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ë¦¬ë·°ë‚˜ ì†Œê°œê¸€ì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ëœ ë‹¨ì–´ë§Œìœ¼ë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´ 'ì „í™”í•˜ê³  ë°©ë¬¸'ì„ 'ì˜ˆì•½'ìœ¼ë¡œ í•´ì„í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë¬¸ë§¥ì„ í™•ì¥í•˜ì—¬ ì¶”ë¡ í•˜ì§€ ë§ˆì„¸ìš”.
- ëª¨ë“  í‚¤ì›Œë“œë¥¼ ì¢…í•©í•˜ì—¬ ì¤‘ë³µì„ ì œê±°í•´ì£¼ì„¸ìš”.
- í•­ëª©ì— í‚¤ì›Œë“œê°€ ì—†ë‹¤ë©´ ë¹ˆ ë°°ì—´ []ì„ ë°˜í™˜í•˜ì„¸ìš”.
- ì‹ë‹¹ ì†Œê°œê¸€ì—ì„œ ë©”ë‰´ëŠ” ì œì™¸ í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ íŠ¹ì§•ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

**JSON í˜•ì‹:**
{{
    "review_food": list,
    "convenience": list,
    "atmosphere": list,
    "occasion": list,
    "features": list,
}}

ìœ„ ê°€ì´ë“œë¼ì¸ê³¼ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬, ì•„ë˜ì˜ ì‹¤ì œ ì…ë ¥ ë°ì´í„°ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì‹ë‹¹ ì†Œê°œê¸€:
{description}

ì‚¬ìš©ì ë¦¬ë·°:
{reviews}
"""


class LLMFeatures(BaseModel):
    review_food: list[str]
    convenience: list[str]
    atmosphere: list[str]
    occasion: list[str]
    features: list[str]


_gemini_client = None
_openai_client = None


def get_gemini_client() -> genai.Client:
    global _gemini_client
    if _gemini_client is None:
        _gemini_client = genai.Client()
    return _gemini_client


def get_openai_client() -> OpenAI:
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAI()
    return _openai_client


def convert_category(category: str) -> str:
    categories = [c.strip() for c in category.split(">")]
    if categories[0] != "ìŒì‹ì ":
        category = categories[0]
    elif len(categories) > 1:
        category = categories[1]

    if "," in category:
        category = [c.strip() for c in category.split(",")]
    else:
        category = [category]

    return category
    

def convert_price_to_int(price_str: str) -> int | None:
    """
    ê°€ê²© ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜
    ì˜ˆ: "20,000ì›" -> 20000
    """
    if not price_str:
        return None
    
    # ìˆ«ìì™€ ì½¤ë§ˆë§Œ ì¶”ì¶œ
    numbers = re.findall(r'[\d,]+', price_str)
    if not numbers:
        return None
    
    # ì½¤ë§ˆ ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜
    try:
        return int(numbers[0].replace(',', ''))
    except ValueError:
        return None


def convert_coordinates(mapx: str, mapy: str) -> tuple[float, float]:
    """
    ë„¤ì´ë²„ ë§µ ì¢Œí‘œë¥¼ ìœ„ë„, ê²½ë„ë¡œ ë³€í™˜
    mapx: ì• ì„¸ ìë¦¬ê°€ ì •ìˆ˜ë¶€, ë‚˜ë¨¸ì§€ê°€ ì†Œìˆ˜ë¶€ (ì˜ˆ: "1271551201" -> 127.1551201)
    mapy: ì• ë‘ ìë¦¬ê°€ ì •ìˆ˜ë¶€, ë‚˜ë¨¸ì§€ê°€ ì†Œìˆ˜ë¶€ (ì˜ˆ: "375630641" -> 37.5630641)
    """

    lat = float(mapy[:2] + '.' + mapy[2:])
    lon = float(mapx[:3] + '.' + mapx[3:])
    
    return lat, lon


def extract_features_with_gemini(place_id: str, reviews: list[str], description: str) -> dict[str, list[str]]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·°ì™€ ì„¤ëª…ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œ
    ì‹¤ì œ êµ¬í˜„ì‹œì—ëŠ” OpenAI API ë“±ì„ ì‚¬ìš©
    """

    num_reviews_to_use = 30
    # ë¦¬ë·° í…ìŠ¤íŠ¸ ê²°í•© (ë„ˆë¬´ ê¸¸ë©´ ì œí•œ)
    review_text = "\n".join(reviews[:num_reviews_to_use])  # ìµœëŒ€ 30ê°œ ë¦¬ë·°ë§Œ ì‚¬ìš©
    if len(review_text) > 100 * num_reviews_to_use:
        review_text = review_text[:100 * num_reviews_to_use]

    user_prompt = EXTRACT_FEATURES_PROMPT.format(description=description, reviews=review_text)

    response = get_gemini_client().models.generate_content(
        model="gemini-2.5-flash",
        contents=user_prompt,
        config=genai.types.GenerateContentConfig(
            temperature=0.0,
            system_instruction=SYSTEM_PROMPT,
            response_mime_type="application/json",
            response_schema=LLMFeatures,
            max_output_tokens=512,
            thinking_config=genai.types.ThinkingConfig(thinking_budget=0),
        )
    )

    response_text = response.text
        
    # LLM ì‘ë‹µì— í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ì„ ì œê±°
    if "```" in response_text:
        match = re.search(r"\{.*\}", response_text, re.DOTALL)
        if match:
            response_text = match.group(0)

    try:
        llm_features = json.loads(response_text)
    except:
        print(f"JSONDecodeError: {place_id}")
        return None

    return llm_features
    

def extract_features_with_openai(place_id: str, reviews: list[str], description: str) -> dict[str, list[str]]:
    num_reviews_to_use = 30
    # ë¦¬ë·° í…ìŠ¤íŠ¸ ê²°í•© (ë„ˆë¬´ ê¸¸ë©´ ì œí•œ)
    review_text = "\n".join(reviews[:num_reviews_to_use])  # ìµœëŒ€ 30ê°œ ë¦¬ë·°ë§Œ ì‚¬ìš©
    if len(review_text) > 100 * num_reviews_to_use:
        review_text = review_text[:100 * num_reviews_to_use]

    user_prompt = EXTRACT_FEATURES_PROMPT.format(description=description, reviews=review_text)

    response = get_openai_client().responses.parse(
        model="gpt-5-mini",
        input=[
            { "role": "system", "content": SYSTEM_PROMPT },
            { "role": "user", "content": user_prompt },
        ],
        text_format=LLMFeatures,
    )

    try:
        llm_features = response.output_parsed.model_dump()
    except:
        print(f"JSONDecodeError: {place_id}")
        return None

    return llm_features

def extract_features(
    place_id: str,
    reviews: list[str],
    description: str,
    platform: str = 'openai',
) -> dict[str, list[str]]:
    if platform == "gemini":
        return extract_features_with_gemini(place_id, reviews, description)
    
    return extract_features_with_openai(place_id, reviews, description)
    


def create_summary(
    title: str,
    category: str,
    address: str,
    road_address: str,
    menus: list[dict], 
    review_food: list[str] | None,
    convenience: list[str] | None,
    atmosphere: list[str] | None, 
    occasion: list[str] | None,
    features: list[str] | None,
) -> str:
    """
    ì„ë² ë”©ì„ ìœ„í•œ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
    """
    # ë©”ë‰´ëª… ì¶”ì¶œ
    menus = [f"{menu.get("name", "")}({menu.get("price", "N/A")}ì›)" for menu in menus if menu.get("name")]
    all_menus = menus + (review_food or [])
    
    summary_parts = [
        f"ì‹ë‹¹ ì´ë¦„: {title}",
        f"ì¹´í…Œê³ ë¦¬: {category}",
        f"ì£¼ì†Œ: {address}({road_address})",
        f"ë©”ë‰´: {','.join(all_menus)}" if all_menus else "ë©”ë‰´: ì •ë³´ ì—†ìŒ"
    ]
    
    if convenience:
        summary_parts.append(f"í¸ì˜: {','.join(convenience)}")
    
    if atmosphere:
        summary_parts.append(f"ë¶„ìœ„ê¸°: {','.join(atmosphere)}")
    
    if occasion:
        summary_parts.append(f"ìƒí™©: {','.join(occasion)}")
    
    if features:
        summary_parts.append(f"ê¸°íƒ€ íŠ¹ì§•: {','.join(features)}")
    
    return "\n".join(summary_parts)



def process_restaurant(raw_data: dict[str, Any], platform: str = 'openai') -> dict[str, Any]:
    """
    ì›ë³¸ ì‹ë‹¹ ë°ì´í„°ë¥¼ ê²€ìƒ‰ìš© ë¬¸ì„œë¡œ ë³€í™˜
    """
    # 1. ì „ì²˜ë¦¬
    # ì¹´í…Œê³ ë¦¬ í´ë¦¬ë‹

    # processed_category = convert_category(raw_data["category"])

    # ê°€ê²© ë³€í™˜
    processed_menus = []
    for menu in raw_data.get("menus", []):
        processed_menu = menu.copy()
        processed_menu["price"] = convert_price_to_int(processed_menu["price"])
        processed_menus.append(processed_menu)
    
    # ìœ„ë„, ê²½ë„ ë³€í™˜
    lat, lon = convert_coordinates(raw_data.get("mapx"), raw_data.get("mapy"))
    
    # 2. LLMì„ ì‚¬ìš©í•œ íŠ¹ì§• ì¶”ì¶œ
    reviews = [review.replace("\n", " ").strip() for review in raw_data.get("reviews", []) if review.replace("\n", " ").strip()]
    reviews = [review for review in raw_data.get("reviews", []) if len(review) >= 15]
    extracted_features = extract_features(
        raw_data["place_id"],
        reviews,
        raw_data.get("description", ""),
        platform
    )

    # 3. ìš”ì•½ ìƒì„±
    summary = create_summary(
        title=raw_data.get("title", ""),
        category=raw_data.get("category"),
        address=raw_data.get("address", ""),
        road_address=raw_data.get("roadAddress", ""),
        menus=processed_menus,
        review_food=extracted_features.get("review_food"),
        convenience=extracted_features.get("convenience"),
        atmosphere=extracted_features.get("atmosphere"),
        occasion=extracted_features.get("occasion"),
        features=extracted_features.get("features")
    )
    
    # 6. ìµœì¢… ë¬¸ì„œ ìƒì„±
    document = {
        "place_id": raw_data.get("place_id"),
        "title": raw_data.get("title"),
        "category": raw_data.get("category"),
        "address": raw_data.get("address"),
        "roadAddress": raw_data.get("roadAddress"),
        "coordinate": {
            "lat": lat,
            "lon": lon,
        },
        "menus": processed_menus,
        "reviews": raw_data.get("reviews", []),
        "description": raw_data.get("description", ""),
        "review_food": extracted_features.get("review_food"),
        "convenience": extracted_features.get("convenience"),
        "atmosphere": extracted_features.get("atmosphere"),
        "occasion": extracted_features.get("occasion"),
        "features": extracted_features.get("features"),
        "summary": summary,
    }
    
    return document


def print_test():
    """
    ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜
    """
    # ì˜ˆì‹œ ë°ì´í„° ì²˜ë¦¬
    sample_data = {
        "place_id": "1993900101",
        "title": "ìš°ë“œë©œë¡œìš°",
        "address": "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬ ê³ ë•ë™ 482",
        "roadAddress": "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬ ì•„ë¦¬ìˆ˜ë¡œ 243",
        "mapx": "1271551201",
        "mapy": "375630641",
        "menus": [
            {"name": "ë©œë€ìë„¤íŒŒë‹¤ë…¸", "price": "20,000ì›"},
            {"name": "ëƒ‰íŒŒìŠ¤íƒ€(ì—¬ë¦„ì‹œì¦Œí•œì •)", "price": "17,500ì›"},
        ],
        "reviews": [
            "ìš°ë“œë©œë¡œìš°ì—ì„œ ë¸ŒëŸ°ì¹˜ë¥¼ ì¦ê¸°ê³  ì™”ì–´ìš”. ê¸´ í…Œì´ë¸”ì´ ìˆì–´ì„œ ë¶€ëª¨ë‹˜ê³¼ ì—¬ëŸ¿ì´ í•¨ê»˜ ì•‰ê¸° í¸í–ˆì–´ìš”.",
            "ë¸ŒëŸ°ì¹˜ ë¨¹ì„ë§Œí•œ ê³³ì„ ì°¾ë‹¤ê°€ ì˜¤í”ˆì‹œê°„ë„ 9ì‹œ 30ë¶„ì´ê³  ê±°ë¦¬ë„ ê°€ê¹Œì›Œì„œ ì™€ë´¤ëŠ”ë° ë¸ŒëŸ°ì¹˜ ë©”ë‰´ê°€ ì •ë§ ë§›ìˆë„¤ìš”"
        ],
        "description": "ì˜ˆì˜ê³  í¸ì•ˆí•œ ê³µê°„ì—ì„œ ë§›ìˆëŠ” ì»¤í”¼ì™€ ë¸ŒëŸ°ì¹˜ë¥¼ ì¦ê²¨ë³´ì„¸ìš” :)"
    }
    
    # ë¬¸ì„œ ì²˜ë¦¬
    document = process_restaurant(sample_data)
    
    # ê²°ê³¼ ì¶œë ¥
    print(json.dumps(document, ensure_ascii=False, indent=2))


def process_single_restaurant(args_tuple):
    """ë‹¨ì¼ ì‹ë‹¹ ë°ì´í„° ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
    raw_data, platform = args_tuple
    try:
        return process_restaurant(raw_data, platform)
    except Exception as e:
        print(f"Error processing {raw_data.get('place_id', 'unknown')}: {e}")
        return None


def main():
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    INPUT_DIR = os.path.join(BASE_DIR, "../../data/crawled_restaurants")
    OUTPUT_DIR = os.path.join(BASE_DIR, "../../data/featured_restaurants")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ì…ë ¥ ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  part íŒŒì¼ ì°¾ê¸°
    input_files = [f for f in os.listdir(INPUT_DIR) if f.startswith("part-") and f.endswith(".jsonl")]
    input_files.sort()  # íŒŒì¼ëª… ìˆœì„œë¡œ ì •ë ¬
    
    print(f"ğŸ“ ì´ {len(input_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘\n")
    
    for file_idx, input_filename in enumerate(input_files, 1):
        input_file_path = os.path.join(INPUT_DIR, input_filename)
        output_file_path = os.path.join(OUTPUT_DIR, input_filename)
        
        print(f"ğŸ“„ [{file_idx}/{len(input_files)}] {input_filename}")
        
        # ì „ì²´ ë ˆì½”ë“œ ìˆ˜ ê³„ì‚°
        total_records = 0
        with open(input_file_path, "r", encoding="utf-8") as f_in:
            for _ in f_in:
                total_records += 1
        
        # ì´ë¯¸ ì²˜ë¦¬ëœ place_idë“¤ í™•ì¸
        processed_place_ids = set()
        if os.path.exists(output_file_path):
            with open(output_file_path, "r", encoding="utf-8") as f_out:
                for line in f_out:
                    document = json.loads(line)
                    processed_place_ids.add(document["place_id"])
        
        processed_count = len(processed_place_ids)
        remaining_count = total_records - processed_count
        
        print(f"ì „ì²´: {total_records}ê°œ | ì™„ë£Œ: {processed_count}ê°œ | ë‚¨ì€ì‘ì—…: {remaining_count}ê°œ")
        
        if remaining_count == 0:
            print("âœ… ì´ë¯¸ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ\n")
            continue
        
        # íŒŒì¼ ì²˜ë¦¬ (ë³‘ë ¬ ì²˜ë¦¬)
        failed_count = 0
        
        # ì²˜ë¦¬í•  ë°ì´í„° ìˆ˜ì§‘
        tasks = []
        with open(input_file_path, "r", encoding="utf-8") as f_in:
            for line in f_in:
                raw_data = json.loads(line)
                if raw_data["place_id"] not in processed_place_ids:
                    tasks.append((raw_data, platform))
        
        # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
        with open(output_file_path, "a", encoding="utf-8") as f_out:
            progress_bar = tqdm(
                total=len(tasks),
                desc="ì²˜ë¦¬ì¤‘",
                unit="ê°œ",
                ncols=80,
                bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
            )
            
            with ThreadPoolExecutor(max_workers=parallelism) as executor:
                # ì‘ì—… ì œì¶œ
                future_to_task = {executor.submit(process_single_restaurant, task): task for task in tasks}
                
                # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
                for future in as_completed(future_to_task):
                    document = future.result()
                    if not document:
                        failed_count += 1
                    else:
                        f_out.write(f"{json.dumps(document, ensure_ascii=False)}\n")
                        f_out.flush()  # ì¦‰ì‹œ íŒŒì¼ì— ì“°ê¸°
                    
                    progress_bar.set_postfix({"ì‹¤íŒ¨": failed_count})
                    progress_bar.update(1)
            
            progress_bar.close()
        
        print(f"âœ… ì™„ë£Œ - ì‹¤íŒ¨: {failed_count}ê°œ\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì‹ë‹¹ ë°ì´í„°ì—ì„œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--platform", 
        choices=["openai", "gemini"], 
        default="openai",
        help="ì‚¬ìš©í•  LLM í”Œë«í¼ (ê¸°ë³¸ê°’: openai)"
    )
    parser.add_argument(
        "--parallelism",
        type=int,
        default=5,
        help="ë™ì‹œ ì²˜ë¦¬í•  ìš”ì²­ ìˆ˜ (ê¸°ë³¸ê°’: 5)"
    )
    
    args = parser.parse_args()
    platform = args.platform
    parallelism = args.parallelism
    
    print(f"ğŸ¤– ì‚¬ìš© í”Œë«í¼: {platform}")
    print(f"ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬: {parallelism}ê°œ ë™ì‹œ ìš”ì²­\n")
    
    main()
